{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Hello, Colaboratory",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "AS6JhAa4Jclb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e01612a8-3de5-4a8c-e575-c78173426478",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526343274416,
          "user_tz": -540,
          "elapsed": 3015,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-B0S0yGZJoGG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "91b07c1a-711f-4eea-c925-cf14a2d56687",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526343307284,
          "user_tz": -540,
          "elapsed": 1252,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "TRAIN_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
        "TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
        "\n",
        "CSV_COLUMN_NAMES = ['SepalLength', 'SepalWidth',\n",
        "                    'PetalLength', 'PetalWidth', 'Species']\n",
        "SPECIES = ['Setosa', 'Versicolor', 'Virginica']\n",
        "\n",
        "def maybe_download():\n",
        "    train_path = tf.keras.utils.get_file(TRAIN_URL.split('/')[-1], TRAIN_URL)\n",
        "    test_path = tf.keras.utils.get_file(TEST_URL.split('/')[-1], TEST_URL)\n",
        "\n",
        "    return train_path, test_path\n",
        "\n",
        "def load_data(y_name='Species'):\n",
        "    \"\"\"Returns the iris dataset as (train_x, train_y), (test_x, test_y).\"\"\"\n",
        "    train_path, test_path = maybe_download()\n",
        "\n",
        "    train = pd.read_csv(train_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "    train_x, train_y = train, train.pop(y_name)\n",
        "\n",
        "    test = pd.read_csv(test_path, names=CSV_COLUMN_NAMES, header=0)\n",
        "    test_x, test_y = test, test.pop(y_name)\n",
        "\n",
        "    return (train_x, train_y), (test_x, test_y)\n",
        "\n",
        "\n",
        "def train_input_fn(features, labels, batch_size):\n",
        "    \"\"\"An input function for training\"\"\"\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
        "\n",
        "    # Shuffle, repeat, and batch the examples.\n",
        "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
        "\n",
        "    # Return the dataset.\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def eval_input_fn(features, labels, batch_size):\n",
        "    \"\"\"An input function for evaluation or prediction\"\"\"\n",
        "    features=dict(features)\n",
        "    if labels is None:\n",
        "        # No labels, use only features.\n",
        "        inputs = features\n",
        "    else:\n",
        "        inputs = (features, labels)\n",
        "\n",
        "    # Convert the inputs to a Dataset.\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(inputs)\n",
        "\n",
        "    # Batch the examples\n",
        "    assert batch_size is not None, \"batch_size must not be None\"\n",
        "    dataset = dataset.batch(batch_size)\n",
        "\n",
        "    # Return the dataset.\n",
        "    return dataset\n",
        "\n",
        "\n",
        "# The remainder of this file contains a simple example of a csv parser,\n",
        "#     implemented using the `Dataset` class.\n",
        "\n",
        "# `tf.parse_csv` sets the types of the outputs to match the examples given in\n",
        "#     the `record_defaults` argument.\n",
        "CSV_TYPES = [[0.0], [0.0], [0.0], [0.0], [0]]\n",
        "\n",
        "def _parse_line(line):\n",
        "    # Decode the line into its fields\n",
        "    fields = tf.decode_csv(line, record_defaults=CSV_TYPES)\n",
        "\n",
        "    # Pack the result into a dictionary\n",
        "    features = dict(zip(CSV_COLUMN_NAMES, fields))\n",
        "\n",
        "    # Separate the label from the features\n",
        "    label = features.pop('Species')\n",
        "\n",
        "    return features, label\n",
        "\n",
        "\n",
        "def csv_input_fn(csv_path, batch_size):\n",
        "    # Create a dataset containing the text lines.\n",
        "    dataset = tf.data.TextLineDataset(csv_path).skip(1)\n",
        "\n",
        "    # Parse each line.\n",
        "    dataset = dataset.map(_parse_line)\n",
        "\n",
        "    # Shuffle, repeat, and batch the examples.\n",
        "    dataset = dataset.shuffle(1000).repeat().batch(batch_size)\n",
        "\n",
        "    # Return the dataset.\n",
        "    return dataset"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h-A5PZ0MJpjI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "1bd6d7b2-d151-4097-bd58-66c287bd0102",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526343343096,
          "user_tz": -540,
          "elapsed": 1423,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KiR6a-acJyKW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "548d2412-e73d-446f-de8f-1945ba835e4b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526343405758,
          "user_tz": -540,
          "elapsed": 981,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          }
        }
      },
      "cell_type": "code",
      "source": [
        "(train_x, train_y), (test_x, test_y) = load_data()\n",
        "my_feature_columns = []\n",
        "for key in train_x.keys():\n",
        "  my_feature_columns.append(tf.feature_column.numeric_column(key=key))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://download.tensorflow.org/data/iris_training.csv\n",
            "\r8192/2194 [================================================================================================================] - 0s 0us/step\n",
            "Downloading data from http://download.tensorflow.org/data/iris_test.csv\n",
            "8192/573 [============================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PAtBletlKBpg",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "dba3a4c3-aaf4-42c9-bae0-8cde466dbefd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526343455794,
          "user_tz": -540,
          "elapsed": 439,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          }
        }
      },
      "cell_type": "code",
      "source": [
        "classifier = tf.estimator.DNNClassifier(\n",
        "    feature_columns=my_feature_columns,\n",
        "    hidden_units=[10, 10],\n",
        "    n_classes=3\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp8dlo1wbw\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmp8dlo1wbw', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7ff73312a710>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5JnT5uhpKNoJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "outputId": "bca496f5-66c9-475a-87ae-f268c8b4a16e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526343498640,
          "user_tz": -540,
          "elapsed": 2939,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          }
        }
      },
      "cell_type": "code",
      "source": [
        "classifier.train(\n",
        "    input_fn=lambda:train_input_fn(train_x, train_y, 100),\n",
        "    steps=1000\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmp8dlo1wbw/model.ckpt.\n",
            "INFO:tensorflow:loss = 158.15547, step = 1\n",
            "INFO:tensorflow:global_step/sec: 666.342\n",
            "INFO:tensorflow:loss = 17.99575, step = 101 (0.152 sec)\n",
            "INFO:tensorflow:global_step/sec: 841.132\n",
            "INFO:tensorflow:loss = 8.759842, step = 201 (0.119 sec)\n",
            "INFO:tensorflow:global_step/sec: 950.919\n",
            "INFO:tensorflow:loss = 8.151076, step = 301 (0.105 sec)\n",
            "INFO:tensorflow:global_step/sec: 890.376\n",
            "INFO:tensorflow:loss = 4.9904547, step = 401 (0.116 sec)\n",
            "INFO:tensorflow:global_step/sec: 896.598\n",
            "INFO:tensorflow:loss = 6.0424995, step = 501 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 939.607\n",
            "INFO:tensorflow:loss = 6.4295497, step = 601 (0.104 sec)\n",
            "INFO:tensorflow:global_step/sec: 868.719\n",
            "INFO:tensorflow:loss = 6.302585, step = 701 (0.114 sec)\n",
            "INFO:tensorflow:global_step/sec: 907.059\n",
            "INFO:tensorflow:loss = 5.8322005, step = 801 (0.111 sec)\n",
            "INFO:tensorflow:global_step/sec: 879.202\n",
            "INFO:tensorflow:loss = 3.0441494, step = 901 (0.114 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp8dlo1wbw/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 5.8044386.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7ff73312a828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "-tOP-Y1xKarV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "24bff424-9d6e-4dbd-c97b-ea77ae037f44",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526343595816,
          "user_tz": -540,
          "elapsed": 1307,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          }
        }
      },
      "cell_type": "code",
      "source": [
        "eval_result = classifier.evaluate(\n",
        "    input_fn=lambda:eval_input_fn(test_x, test_y, 100)\n",
        ")\n",
        "print('Test set accuracy: {accuracy:0.3f}'.format(**eval_result))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Starting evaluation at 2018-05-15-00:19:55\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp8dlo1wbw/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Finished evaluation at 2018-05-15-00:19:55\n",
            "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.96666664, average_loss = 0.057581563, global_step = 1000, loss = 1.7274469\n",
            "Test set accuracy: 0.967\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KocXm0yLKyuh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "2ae5b3d1-473a-4b75-d5f1-2589434aca57",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526343736417,
          "user_tz": -540,
          "elapsed": 971,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          }
        }
      },
      "cell_type": "code",
      "source": [
        "expected = ['Setosa', 'Versicolor', 'Virginica']\n",
        "predict_x = {\n",
        "    'SepalLength': [5.1, 5.9, 6.9],\n",
        "    'SepalWidth': [3.3, 3.0, 3.1],\n",
        "    'PetalLength': [1.7, 4.2, 5.4],\n",
        "    'PetalWidth': [0.5, 1.5, 2.1]\n",
        "}\n",
        "\n",
        "predictions = classifier.predict(\n",
        "    input_fn=lambda:eval_input_fn(predict_x, labels=None, batch_size=100)\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WEg3llgKLSsb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "04fc9ab4-9b86-4943-8dd8-8428247242a8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1526343862633,
          "user_tz": -540,
          "elapsed": 1099,
          "user": {
            "displayName": "",
            "photoUrl": "",
            "userId": ""
          }
        }
      },
      "cell_type": "code",
      "source": [
        "template = ('Prediction is \"{}\" ({:.1f}%), expected \"{}\"')\n",
        "\n",
        "for pred_dict, expec in zip(predictions, expected):\n",
        "  class_id = pred_dict['class_ids'][0]\n",
        "  probability = pred_dict['probabilities'][class_id]\n",
        "  print(template.format(SPECIES[class_id], 100 * probability, expec))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmp8dlo1wbw/model.ckpt-1000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "Prediction is \"Setosa\" (99.8%), expected \"Setosa\"\n",
            "Prediction is \"Versicolor\" (99.7%), expected \"Versicolor\"\n",
            "Prediction is \"Virginica\" (96.0%), expected \"Virginica\"\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}